name: gpt faster scraper

on:
  workflow_dispatch:

concurrency:
  group: news-scraper
  cancel-in-progress: false

jobs:
  scrape_news:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: false
          fetch-depth: 0

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Cache HuggingFace Models
        uses: actions/cache@v3
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-huggingface-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-huggingface-

      # Install Chrome
      - name: Install Chrome
        uses: browser-actions/setup-chrome@v1

      # Install ChromeDriver using correct Google public bucket
      - name: Install matching ChromeDriver
        run: |
          set -euo pipefail

          CHROME_FULL_VERSION=$(google-chrome --version | sed 's/[^0-9.]//g')
          MAJOR_VERSION=$(echo "$CHROME_FULL_VERSION" | cut -d'.' -f1)
          echo "Chrome installed: $CHROME_FULL_VERSION (major: $MAJOR_VERSION)"

          DRIVER_VERSION=$(wget -qO- "https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_${MAJOR_VERSION}" || true)
          if [ -z "$DRIVER_VERSION" ]; then
            DRIVER_VERSION=$(wget -qO- "https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE")
          fi

          echo "Matching ChromeDriver version: $DRIVER_VERSION"

          DRIVER_URL="https://storage.googleapis.com/chrome-for-testing-public/${DRIVER_VERSION}/linux64/chromedriver-linux64.zip"
          echo "Downloading ChromeDriver from: $DRIVER_URL"

          wget -q "$DRIVER_URL" -O /tmp/chromedriver.zip
          unzip -q /tmp/chromedriver.zip -d /tmp/chromedriver_extract

          sudo mv /tmp/chromedriver_extract/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
          sudo chmod +x /usr/local/bin/chromedriver

          rm -rf /tmp/chromedriver.zip /tmp/chromedriver_extract

          echo "ChromeDriver installed."

      # Xvfb for stability
      - name: Start Xvfb
        run: |
          sudo apt-get update
          sudo apt-get install -y xvfb
          Xvfb :99 -screen 0 1920x1080x24 &

      # Install Python deps
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install torch --index-url https://download.pytorch.org/whl/cpu
          pip install -r requirements.txt
          pip install requests beautifulsoup4 trafilatura selenium sentence-transformers

      # Run scraper
      - name: Run scraper
        env:
          DISPLAY: :99
        run: |
          python news_scraper_AI_faster.py

      # Save logs
      - name: Save logs with timestamp
        run: |
          mkdir -p logs
          TS=$(date +"%Y%m%d_%H%M%S")
          LOG="logs/scraper_${TS}_run${{ github.run_number }}.log"
          if [ -f news_scraper.log ]; then cp news_scraper.log "$LOG"; fi

      # Commit DB + logs
      - name: Commit and push updated database and logs
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git

          git add news_articles.db logs/ || true

          if ! git diff --staged --quiet; then
            git commit -m "Update DB and logs [skip ci]" || true
            git pull --rebase origin main || true
            git push origin HEAD:main || true
          fi
